{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Model Summary \n",
    "## The goals of this model:\n",
    "* Sentiment analysis of Tweets \n",
    "* Predidct positive/ neutral/negative signals of BTC price\n",
    "* Label future Tweets\n",
    "\n",
    "## Approach\n",
    "* NLP and sentimental analysis \n",
    "* Bi-directional LSTM model\n",
    "\n",
    "## Data \n",
    "* BTC price \n",
    "* Tweets \n",
    "\n",
    "1. Sample the data randomly and normlize the data. \n",
    "2. Find the derivative of BTC prices and define their positive/negative/neutral signals \n",
    "3. Defind a classification problem that predicts the movement\n",
    "4. use the model to further label data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2022-02-04T21:48:46.168863Z",
     "iopub.execute_input": "2022-02-04T21:48:46.169175Z",
     "iopub.status.idle": "2022-02-04T21:48:46.214208Z",
     "shell.execute_reply.started": "2022-02-04T21:48:46.169079Z",
     "shell.execute_reply": "2022-02-04T21:48:46.213182Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "! pip install vaderSentiment"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-04T21:48:46.215954Z",
     "iopub.execute_input": "2022-02-04T21:48:46.216837Z",
     "iopub.status.idle": "2022-02-04T21:48:56.579468Z",
     "shell.execute_reply.started": "2022-02-04T21:48:46.2168Z",
     "shell.execute_reply": "2022-02-04T21:48:56.57859Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# download stopwords\n",
    "import  nltk\n",
    "nltk.download('punkt')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-04T21:53:17.648886Z",
     "iopub.execute_input": "2022-02-04T21:53:17.649361Z",
     "iopub.status.idle": "2022-02-04T21:53:33.788343Z",
     "shell.execute_reply.started": "2022-02-04T21:53:17.649284Z",
     "shell.execute_reply": "2022-02-04T21:53:33.78767Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\yedih\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from time import sleep\n",
    "import json\n",
    "import pandas as pd\n",
    "import io\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from tqdm import tnrange, tqdm_notebook, tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "# from plotly.offline import init_notebook_mode, iplot\n",
    "# import plotly.graph_objs as go\n",
    "# init_notebook_mode(connected=True) "
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T00:41:22.385287Z",
     "iopub.execute_input": "2022-02-03T00:41:22.385557Z",
     "iopub.status.idle": "2022-02-03T00:41:23.457641Z",
     "shell.execute_reply.started": "2022-02-03T00:41:22.385526Z",
     "shell.execute_reply": "2022-02-03T00:41:23.456829Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tweets_raw_file   = './Bitcoin_tweets.csv'\n",
    "tweets_clean_file = './Bitcoin_tweets_clean.csv'\n",
    "bit_price_file2 = './bitcoin-price-history/BTC-USD.csv'\n",
    "# bit_price_file2 = 'data/BTC-USD.csv'"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T00:41:35.260452Z",
     "iopub.execute_input": "2022-02-03T00:41:35.261014Z",
     "iopub.status.idle": "2022-02-03T00:41:35.26524Z",
     "shell.execute_reply.started": "2022-02-03T00:41:35.260981Z",
     "shell.execute_reply": "2022-02-03T00:41:35.264466Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# limit reading for testing\n",
    "df_raw = pd.read_csv(tweets_raw_file,low_memory=False, nrows=5000)\n",
    "#df_raw = pd.read_csv(tweets_raw_file,low_memory=False)\n",
    "print(df_raw.shape)\n",
    "df_raw.head(5)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T00:41:37.694522Z",
     "iopub.execute_input": "2022-02-03T00:41:37.694811Z",
     "iopub.status.idle": "2022-02-03T00:42:13.952696Z",
     "shell.execute_reply.started": "2022-02-03T00:41:37.694779Z",
     "shell.execute_reply": "2022-02-03T00:42:13.951876Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                  user_name    user_location  \\\n0                             DeSota Wilson      Atlanta, GA   \n1                                  CryptoND              NaN   \n2                                 Tdlmatias  London, England   \n3                      Crypto is the future              NaN   \n4  Alex Kirchmaier ðŸ‡¦ðŸ‡¹ðŸ‡¸ðŸ‡ª #FactsSuperspreader           Europa   \n\n                                    user_description         user_created  \\\n0  Biz Consultant, real estate, fintech, startups...  2009-04-26 20:05:09   \n1  ðŸ˜Ž BITCOINLIVE is a Dutch platform aimed at inf...  2019-10-17 20:12:10   \n2  IM Academy : The best #forex, #SelfEducation, ...  2014-11-10 10:50:37   \n3  I will post a lot of buying signals for BTC tr...  2019-09-28 16:48:12   \n4  Co-founder @RENJERJerky | Forbes 30Under30 | I...  2016-02-03 13:15:55   \n\n   user_followers  user_friends  user_favourites  user_verified  \\\n0          8534.0          7605             4838          False   \n1          6769.0          1532            25483          False   \n2           128.0           332              924          False   \n3           625.0           129               14          False   \n4          1249.0          1472            10482          False   \n\n                  date                                               text  \\\n0  2021-02-10 23:59:04  Blue Ridge Bank shares halted by NYSE after #b...   \n1  2021-02-10 23:58:48  ðŸ˜Ž Today, that's this #Thursday, we will do a \"...   \n2  2021-02-10 23:54:48  Guys evening, I have read this article about B...   \n3  2021-02-10 23:54:33  $BTC A big chance in a billion! Price: \\487264...   \n4  2021-02-10 23:54:06  This network is secured by 9 508 nodes as of t...   \n\n                                    hashtags               source  is_retweet  \n0                                ['bitcoin']      Twitter Web App       False  \n1  ['Thursday', 'Btc', 'wallet', 'security']  Twitter for Android       False  \n2                                        NaN      Twitter Web App       False  \n3         ['Bitcoin', 'FX', 'BTC', 'crypto']              dlvr.it       False  \n4                                    ['BTC']      Twitter Web App       False  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_name</th>\n      <th>user_location</th>\n      <th>user_description</th>\n      <th>user_created</th>\n      <th>user_followers</th>\n      <th>user_friends</th>\n      <th>user_favourites</th>\n      <th>user_verified</th>\n      <th>date</th>\n      <th>text</th>\n      <th>hashtags</th>\n      <th>source</th>\n      <th>is_retweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>DeSota Wilson</td>\n      <td>Atlanta, GA</td>\n      <td>Biz Consultant, real estate, fintech, startups...</td>\n      <td>2009-04-26 20:05:09</td>\n      <td>8534.0</td>\n      <td>7605</td>\n      <td>4838</td>\n      <td>False</td>\n      <td>2021-02-10 23:59:04</td>\n      <td>Blue Ridge Bank shares halted by NYSE after #b...</td>\n      <td>['bitcoin']</td>\n      <td>Twitter Web App</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CryptoND</td>\n      <td>NaN</td>\n      <td>ðŸ˜Ž BITCOINLIVE is a Dutch platform aimed at inf...</td>\n      <td>2019-10-17 20:12:10</td>\n      <td>6769.0</td>\n      <td>1532</td>\n      <td>25483</td>\n      <td>False</td>\n      <td>2021-02-10 23:58:48</td>\n      <td>ðŸ˜Ž Today, that's this #Thursday, we will do a \"...</td>\n      <td>['Thursday', 'Btc', 'wallet', 'security']</td>\n      <td>Twitter for Android</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Tdlmatias</td>\n      <td>London, England</td>\n      <td>IM Academy : The best #forex, #SelfEducation, ...</td>\n      <td>2014-11-10 10:50:37</td>\n      <td>128.0</td>\n      <td>332</td>\n      <td>924</td>\n      <td>False</td>\n      <td>2021-02-10 23:54:48</td>\n      <td>Guys evening, I have read this article about B...</td>\n      <td>NaN</td>\n      <td>Twitter Web App</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Crypto is the future</td>\n      <td>NaN</td>\n      <td>I will post a lot of buying signals for BTC tr...</td>\n      <td>2019-09-28 16:48:12</td>\n      <td>625.0</td>\n      <td>129</td>\n      <td>14</td>\n      <td>False</td>\n      <td>2021-02-10 23:54:33</td>\n      <td>$BTC A big chance in a billion! Price: \\487264...</td>\n      <td>['Bitcoin', 'FX', 'BTC', 'crypto']</td>\n      <td>dlvr.it</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Alex Kirchmaier ðŸ‡¦ðŸ‡¹ðŸ‡¸ðŸ‡ª #FactsSuperspreader</td>\n      <td>Europa</td>\n      <td>Co-founder @RENJERJerky | Forbes 30Under30 | I...</td>\n      <td>2016-02-03 13:15:55</td>\n      <td>1249.0</td>\n      <td>1472</td>\n      <td>10482</td>\n      <td>False</td>\n      <td>2021-02-10 23:54:06</td>\n      <td>This network is secured by 9 508 nodes as of t...</td>\n      <td>['BTC']</td>\n      <td>Twitter Web App</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# clean df \n",
    "df_raw = df_raw.sort_values(by = 'date')\n",
    "dd = df_raw.sample(frac=0.01, replace=False, random_state=1)\n",
    "dd.reset_index(inplace=True)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "for i,s in enumerate(tqdm(dd['text'],position=0, leave=True)):\n",
    "    text = str(dd.loc[i, 'text'])\n",
    "    text = text.replace(\"#\", \"\")\n",
    "    # remove URL\n",
    "    text = re.sub('https?://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+', '', text, flags=re.MULTILINE)\n",
    "    # remove 'at'\n",
    "    text = re.sub('@\\\\w+ *', '', text, flags=re.MULTILINE)\n",
    "    # remove stopwords\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "    text = ' '.join(filtered_sentence)\n",
    "    dd.loc[i, 'text'] = text\n",
    "# f = open(tweets_clean_file, 'a+', encoding='utf-8')\n",
    "dd.to_csv(tweets_clean_file, header=True, encoding='utf-8',index=False)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T00:42:34.529263Z",
     "iopub.execute_input": "2022-02-03T00:42:34.529677Z",
     "iopub.status.idle": "2022-02-03T00:43:25.361916Z",
     "shell.execute_reply.started": "2022-02-03T00:42:34.529641Z",
     "shell.execute_reply": "2022-02-03T00:43:25.36114Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:00<00:00, 3085.50it/s]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sentiment anatweets_clean_fileh Vader\n",
    "VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media.\n",
    "\n",
    "VADER takes into account\n",
    "\n",
    "negations and contractions (not good, wasnâ€™t good)\n",
    "Punctuation (good!!!), CAPS, emotes :), emojis\n",
    "Intensificators (very, kind of), acronyms â€˜lolâ€™\n",
    "Scores between -1.0 (negative) and 1.0 (positive)\n",
    "\n",
    "We will use this sentiment analysis of the tweets to calculate a score that will represent the importance of each tweet."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "df_clean = pd.read_csv(tweets_clean_file)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T00:46:02.954902Z",
     "iopub.execute_input": "2022-02-03T00:46:02.955347Z",
     "iopub.status.idle": "2022-02-03T00:46:03.158304Z",
     "shell.execute_reply.started": "2022-02-03T00:46:02.955316Z",
     "shell.execute_reply": "2022-02-03T00:46:03.15718Z"
    },
    "trusted": true
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "compound = []\n",
    "for i,s in enumerate(tqdm(df_clean['text'],position=0, leave=True)):\n",
    "    # print(i,s)\n",
    "    vs = analyzer.polarity_scores(str(s))\n",
    "    compound.append(vs[\"compound\"])\n",
    "df_clean[\"compound\"] = compound\n",
    "df_clean.head(2)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T00:46:03.893007Z",
     "iopub.execute_input": "2022-02-03T00:46:03.893619Z",
     "iopub.status.idle": "2022-02-03T00:46:08.506478Z",
     "shell.execute_reply.started": "2022-02-03T00:46:03.893577Z",
     "shell.execute_reply": "2022-02-03T00:46:08.5056Z"
    },
    "trusted": true
   },
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:00<00:00, 12481.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "   index            user_name user_location  \\\n0   2235  The Bitcoin News ðŸš€â‚¿  The Internet   \n1    232           Joe Martin           NaN   \n\n                                    user_description         user_created  \\\n0  #Bitcoin #Blockchain Advertise https://t.co/rp...  2013-04-11 02:30:32   \n1  Bitcoin, Blockchain & Co. â€“ The Truth, and Not...  2017-10-14 09:36:42   \n\n   user_followers  user_friends  user_favourites  user_verified  \\\n0         63635.0         20787               80          False   \n1           327.0           941               57          False   \n\n                  date                                               text  \\\n0  2021-02-10 10:09:27  Overall Bitcoin-related Crime fell last year -...   \n1  2021-02-10 22:06:03  people involved , greater recognition opportun...   \n\n                                            hashtags            source  \\\n0  ['Bitcoin', 'Crime', 'bitcoin', 'btc', 'bitcoi...  The Bitcoin News   \n1                                                NaN       SocialOomph   \n\n   is_retweet  compound  \n0       False   -0.5423  \n1       False    0.6486  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>user_name</th>\n      <th>user_location</th>\n      <th>user_description</th>\n      <th>user_created</th>\n      <th>user_followers</th>\n      <th>user_friends</th>\n      <th>user_favourites</th>\n      <th>user_verified</th>\n      <th>date</th>\n      <th>text</th>\n      <th>hashtags</th>\n      <th>source</th>\n      <th>is_retweet</th>\n      <th>compound</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2235</td>\n      <td>The Bitcoin News ðŸš€â‚¿</td>\n      <td>The Internet</td>\n      <td>#Bitcoin #Blockchain Advertise https://t.co/rp...</td>\n      <td>2013-04-11 02:30:32</td>\n      <td>63635.0</td>\n      <td>20787</td>\n      <td>80</td>\n      <td>False</td>\n      <td>2021-02-10 10:09:27</td>\n      <td>Overall Bitcoin-related Crime fell last year -...</td>\n      <td>['Bitcoin', 'Crime', 'bitcoin', 'btc', 'bitcoi...</td>\n      <td>The Bitcoin News</td>\n      <td>False</td>\n      <td>-0.5423</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>232</td>\n      <td>Joe Martin</td>\n      <td>NaN</td>\n      <td>Bitcoin, Blockchain &amp; Co. â€“ The Truth, and Not...</td>\n      <td>2017-10-14 09:36:42</td>\n      <td>327.0</td>\n      <td>941</td>\n      <td>57</td>\n      <td>False</td>\n      <td>2021-02-10 22:06:03</td>\n      <td>people involved , greater recognition opportun...</td>\n      <td>NaN</td>\n      <td>SocialOomph</td>\n      <td>False</td>\n      <td>0.6486</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate a score for each tweet\n",
    "To calculate the score for each tweet, we use different variables to which we had a weight based on its importance.\n",
    "\n",
    "The compound column represents the sentiment of the tweets and its value is between -1 and 1.\n",
    "\n",
    "We also use the number of retweets, the number of likes, and the number of users that follow the tweet's author."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "scores = []\n",
    "for i, s in tqdm(df_clean.iterrows(), total=df_clean.shape[0],position=0, leave=True):\n",
    "    try:\n",
    "        scores.append(s[\"compound\"] * ((int(s[\"user_followers\"]))) * ((int(s[\"user_favourites\"])+1)/int(s['user_followers']+1)) *((int(s[\"is_retweet\"])+1)))\n",
    "    except:\n",
    "        scores.append(np.nan)\n",
    "df_clean[\"score\"] = scores\n",
    "df_clean.head(2)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:16:31.191404Z",
     "iopub.execute_input": "2022-02-03T01:16:31.19182Z",
     "iopub.status.idle": "2022-02-03T01:16:32.982655Z",
     "shell.execute_reply.started": "2022-02-03T01:16:31.191781Z",
     "shell.execute_reply": "2022-02-03T01:16:32.982087Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## read Bitcoin price "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "df_price = pd.read_csv(bit_price_file2)\n",
    "df_price.Date = pd.to_datetime(df_price.Date)\n",
    "# df_price.Timestamp = pd.to_datetime(df_price.Timestamp,unit='s')\n",
    "df_price.head(2)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:16:32.984044Z",
     "iopub.execute_input": "2022-02-03T01:16:32.9843Z",
     "iopub.status.idle": "2022-02-03T01:16:33.007842Z",
     "shell.execute_reply.started": "2022-02-03T01:16:32.984271Z",
     "shell.execute_reply": "2022-02-03T01:16:33.00697Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# sentiment analysis \n",
    "df_clean = df_clean.drop_duplicates()\n",
    "tweets = df_clean.copy()\n",
    "tweets['date'] = pd.to_datetime(tweets['date'],utc=True)\n",
    "tweets.date = tweets.date.dt.tz_localize(None)\n",
    "tweets.index = tweets['date']\n",
    "\n",
    "# tweets_grouped = tweets.groupby(pd.TimeGrouper('1h'))['score'].sum()\n",
    "tweets_grouped = tweets.resample('1h').sum()\n",
    "\n",
    "crypto_usd = df_price.copy()\n",
    "crypto_usd['Date'] = pd.to_datetime(crypto_usd['Date'], unit='s')\n",
    "crypto_usd.index = crypto_usd['Date']\n",
    "# crypto_usd['Timestamp'] = pd.to_datetime(crypto_usd['Timestamp'], unit='s')\n",
    "# crypto_usd.index = crypto_usd['Timestamp']\n",
    "\n",
    "# crypto_usd_grouped = crypto_usd.groupby(pd.TimeGrouper('1h'))['Weighted_Price'].mean()\n",
    "crypto_usd_grouped = crypto_usd.resample('D')['Close'].mean()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:16:33.00943Z",
     "iopub.execute_input": "2022-02-03T01:16:33.009863Z",
     "iopub.status.idle": "2022-02-03T01:16:33.117454Z",
     "shell.execute_reply.started": "2022-02-03T01:16:33.009817Z",
     "shell.execute_reply": "2022-02-03T01:16:33.116732Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def crosscorr(datax, datay, lag=0, method=\"pearson\"):\n",
    "    \"\"\" Lag-N cross correlation. \n",
    "    Parameters\n",
    "    â€”------â€”\n",
    "    lag : int, default 0\n",
    "    datax, datay : pandas.Series objects of equal length\n",
    "\n",
    "    Returns\n",
    "    â€”------â€”\n",
    "    crosscorr : float\n",
    "    \"\"\"\n",
    "    return datax.corrwith(datay.shift(lag), method=method)['score']\n",
    "# xcov = [crosscorr(tweets_grouped, crypto_usd_grouped, lag=i, m ='pearson' ) for i in range(-20,20)]\n",
    "# tweets_grouped.corrwith(crypto_usd_grouped,method='pearson')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:16:33.119093Z",
     "iopub.execute_input": "2022-02-03T01:16:33.119304Z",
     "iopub.status.idle": "2022-02-03T01:16:33.123672Z",
     "shell.execute_reply.started": "2022-02-03T01:16:33.119279Z",
     "shell.execute_reply": "2022-02-03T01:16:33.123122Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "beggining = max(tweets_grouped.index.min().replace(tzinfo=None), crypto_usd_grouped.index.min())\n",
    "end = min(tweets_grouped.index.max().replace(tzinfo=None), crypto_usd_grouped.index.max())\n",
    "tweets_grouped = tweets_grouped[beggining:end]\n",
    "crypto_usd_grouped = crypto_usd_grouped[beggining:end]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:16:33.124654Z",
     "iopub.execute_input": "2022-02-03T01:16:33.12484Z",
     "iopub.status.idle": "2022-02-03T01:16:33.13731Z",
     "shell.execute_reply.started": "2022-02-03T01:16:33.124818Z",
     "shell.execute_reply": "2022-02-03T01:16:33.136479Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "fig, ax1 = plt.subplots(figsize=(20,10))\n",
    "ax1.set_title(\"Crypto currency evolution compared to twitter sentiment\", fontsize=18)\n",
    "ax1.tick_params(labelsize=14)\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot_date(tweets_grouped.index, tweets_grouped, 'g-')\n",
    "ax2.plot_date(crypto_usd_grouped.index, crypto_usd_grouped, 'b-')\n",
    "\n",
    "ax1.set_ylabel(\"Sentiment\", color='g', fontsize=16)\n",
    "ax2.set_ylabel(\"Bitcoin [$]\", color='b', fontsize=16)\n",
    "plt.show()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:16:33.266299Z",
     "iopub.execute_input": "2022-02-03T01:16:33.266579Z",
     "iopub.status.idle": "2022-02-03T01:16:33.642703Z",
     "shell.execute_reply.started": "2022-02-03T01:16:33.266548Z",
     "shell.execute_reply": "2022-02-03T01:16:33.642056Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "xcov = [crosscorr(tweets_grouped, crypto_usd_grouped, lag=i, method=\"pearson\") for i in range(-20,20)]\n",
    "plt.plot(range(-20,20), xcov)\n",
    "plt.title(\"pearson cross-correlation\")\n",
    "plt.xlabel(\"lag\")\n",
    "plt.ylabel(\"correlation\")\n",
    "plt.show()\n",
    "\n",
    "xcov = [crosscorr(tweets_grouped, crypto_usd_grouped, lag=i, method=\"kendall\") for i in range(-20,20)]\n",
    "plt.plot(range(-20,20), xcov)\n",
    "plt.title(\"kendall cross-correlation\")\n",
    "plt.xlabel(\"lag\")\n",
    "plt.ylabel(\"correlation\")\n",
    "plt.show()\n",
    "\n",
    "xcov = [crosscorr(tweets_grouped, crypto_usd_grouped, lag=i, method=\"spearman\") for i in range(-20,20)]\n",
    "plt.plot(range(-20,20), xcov)\n",
    "plt.title(\"spearman cross-correlation\")\n",
    "plt.xlabel(\"lag\")\n",
    "plt.ylabel(\"correlation\")\n",
    "plt.show()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:16:35.71392Z",
     "iopub.execute_input": "2022-02-03T01:16:35.714708Z",
     "iopub.status.idle": "2022-02-03T01:16:37.146918Z",
     "shell.execute_reply.started": "2022-02-03T01:16:35.714673Z",
     "shell.execute_reply": "2022-02-03T01:16:37.146127Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Normalization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Normalize time series data\n",
    "min_max_scaler = preprocessing.StandardScaler()\n",
    "score_scaled = min_max_scaler.fit_transform(tweets_grouped['score'].values.reshape(-1,1))\n",
    "tweets_grouped['normalized_score'] = score_scaled\n",
    "# crypto_used_grouped_scaled = min_max_scaler.fit_transform(crypto_usd_grouped.values.reshape(-1,1))\n",
    "crypto_used_grouped_scaled = crypto_usd_grouped / max(crypto_usd_grouped.max(), abs(crypto_usd_grouped.min()))\n",
    "# crypto_usd_grouped['normalized_price'] = crypto_used_grouped_scaled\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(20,10))\n",
    "ax1.set_title(\"Normalized Crypto currency evolution compared to normalized twitter sentiment\", fontsize=18)\n",
    "ax1.tick_params(labelsize=14)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot_date(tweets_grouped.index, tweets_grouped['normalized_score'], 'g-')\n",
    "ax2.plot_date(crypto_usd_grouped.index, crypto_used_grouped_scaled, 'b-')\n",
    "\n",
    "ax1.set_ylabel(\"Sentiment\", color='g', fontsize=16)\n",
    "ax2.set_ylabel(\"Bitcoin normalized\", color='b', fontsize=16)\n",
    "plt.show()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:16:37.169855Z",
     "iopub.execute_input": "2022-02-03T01:16:37.170395Z",
     "iopub.status.idle": "2022-02-03T01:16:37.545923Z",
     "shell.execute_reply.started": "2022-02-03T01:16:37.170358Z",
     "shell.execute_reply": "2022-02-03T01:16:37.545375Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#tweets_grouped.T.corr(crypto_usd_grouped, method='pearson')\n",
    "#tweets_grouped.T.autocorr(crypto_usd_grouped, lag=20)\n",
    "xcov = [crosscorr(tweets_grouped, crypto_usd_grouped, lag=i) for i in range(-20,20)]\n",
    "plt.plot(range(-20,20), xcov)\n",
    "plt.title(\"lag's impact on correlation (normalized)\")\n",
    "plt.xlabel(\"lag\")\n",
    "plt.ylabel(\"correlation\")\n",
    "plt.show()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:16:39.291329Z",
     "iopub.execute_input": "2022-02-03T01:16:39.291623Z",
     "iopub.status.idle": "2022-02-03T01:16:39.728074Z",
     "shell.execute_reply.started": "2022-02-03T01:16:39.291595Z",
     "shell.execute_reply": "2022-02-03T01:16:39.726987Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Derivative of Crypto price "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Derivative\n",
    "tweets_grouped_derivative = pd.Series(np.gradient(tweets_grouped['normalized_score'].values), tweets_grouped.index, name='slope')\n",
    "crypto_usd_grouped_derivative = pd.Series(np.gradient(crypto_usd_grouped.values), crypto_usd_grouped.index, name='slope')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:16:44.46536Z",
     "iopub.execute_input": "2022-02-03T01:16:44.465633Z",
     "iopub.status.idle": "2022-02-03T01:16:44.471247Z",
     "shell.execute_reply.started": "2022-02-03T01:16:44.465605Z",
     "shell.execute_reply": "2022-02-03T01:16:44.470581Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "fig, ax1 = plt.subplots(figsize=(20,10))\n",
    "ax1.set_title(\"Derivative of crypto currency and sentiment's score\", fontsize=18)\n",
    "ax1.tick_params(labelsize=14)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot_date(tweets_grouped_derivative.index, tweets_grouped_derivative, 'g-')\n",
    "ax2.plot_date(crypto_usd_grouped_derivative.index, crypto_usd_grouped_derivative, 'b-')\n",
    "\n",
    "ax1.set_ylabel(\"Sentiment's derivative\", color='g', fontsize=16)\n",
    "ax2.set_ylabel('Bitcoin price derivative', color='b', fontsize=16)\n",
    "plt.show()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:16:45.599803Z",
     "iopub.execute_input": "2022-02-03T01:16:45.600937Z",
     "iopub.status.idle": "2022-02-03T01:16:46.032142Z",
     "shell.execute_reply.started": "2022-02-03T01:16:45.600865Z",
     "shell.execute_reply": "2022-02-03T01:16:46.031008Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "xcov = [crosscorr(tweets_grouped, crypto_usd_grouped_derivative, lag=i, method=\"pearson\") for i in range(-20,20)]\n",
    "plt.plot(range(-20,20), xcov)\n",
    "plt.title(\"pearson cross-corelation (derivative)\")\n",
    "plt.xlabel(\"lag\")\n",
    "plt.ylabel(\"correlation\")\n",
    "plt.show()\n",
    "\n",
    "xcov = [crosscorr(tweets_grouped, crypto_usd_grouped_derivative, lag=i, method=\"kendall\") for i in range(-20,20)]\n",
    "plt.plot(range(-20,20), xcov)\n",
    "plt.title(\"kendall cross-corelation (derivative)\")\n",
    "plt.xlabel(\"lag\")\n",
    "plt.ylabel(\"correlation\")\n",
    "plt.show()\n",
    "\n",
    "xcov = [crosscorr(tweets_grouped, crypto_usd_grouped_derivative, lag=i, method=\"spearman\") for i in range(-20,20)]\n",
    "plt.plot(range(-20,20), xcov)\n",
    "plt.title(\"spearman cross-corelation (derivative)\")\n",
    "plt.xlabel(\"lag\")\n",
    "plt.ylabel(\"correlation\")\n",
    "plt.show()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:16:46.479505Z",
     "iopub.execute_input": "2022-02-03T01:16:46.47985Z",
     "iopub.status.idle": "2022-02-03T01:16:48.053962Z",
     "shell.execute_reply.started": "2022-02-03T01:16:46.479818Z",
     "shell.execute_reply": "2022-02-03T01:16:48.053147Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 2 NLP Modeling "
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-30T00:57:23.278619Z",
     "iopub.execute_input": "2022-01-30T00:57:23.278911Z",
     "iopub.status.idle": "2022-01-30T00:57:23.283161Z",
     "shell.execute_reply.started": "2022-01-30T00:57:23.278882Z",
     "shell.execute_reply": "2022-01-30T00:57:23.282262Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "! pip install textblob \n",
    "from textblob import TextBlob\n",
    "\n",
    "df = df_clean.copy()\n",
    "df.dropna(subset=['hashtags'], inplace=True)\n",
    "df = df[['text']] \n",
    "df.columns = ['tweets']\n",
    "df.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:24:40.085817Z",
     "iopub.execute_input": "2022-02-03T01:24:40.086907Z",
     "iopub.status.idle": "2022-02-03T01:24:48.974225Z",
     "shell.execute_reply.started": "2022-02-03T01:24:40.086841Z",
     "shell.execute_reply": "2022-02-03T01:24:48.973208Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = nltk.corpus.stopwords.words(['english'])\n",
    "\n",
    "print(stop_words)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:24:48.976425Z",
     "iopub.execute_input": "2022-02-03T01:24:48.976806Z",
     "iopub.status.idle": "2022-02-03T01:24:48.986755Z",
     "shell.execute_reply.started": "2022-02-03T01:24:48.976773Z",
     "shell.execute_reply": "2022-02-03T01:24:48.985659Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "def cleaning(data):\n",
    "    #remove urls\n",
    "    tweet_without_url = re.sub(r'http\\S+',' ', data)\n",
    "\n",
    "    #remove hashtags\n",
    "    tweet_without_hashtag = re.sub(r'#\\w+', ' ', tweet_without_url)\n",
    "\n",
    "    #3. Remove mentions and characters that not in the English alphabets\n",
    "    tweet_without_mentions = re.sub(r'@\\w+',' ', tweet_without_hashtag)\n",
    "    precleaned_tweet = re.sub('[^A-Za-z]+', ' ', tweet_without_mentions)\n",
    "\n",
    "    #2. Tokenize\n",
    "    tweet_tokens = TweetTokenizer().tokenize(precleaned_tweet)\n",
    "\n",
    "    #3. Remove Puncs\n",
    "    tokens_without_punc = [w for w in tweet_tokens if w.isalpha()]\n",
    "\n",
    "    #4. Removing Stopwords\n",
    "    tokens_without_sw = [t for t in tokens_without_punc if t not in stop_words]\n",
    "\n",
    "    #5. lemma\n",
    "    text_cleaned = [lem.lemmatize(t) for t in tokens_without_sw]\n",
    "\n",
    "    #6. Joining\n",
    "    return \" \".join(text_cleaned)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:24:48.988184Z",
     "iopub.execute_input": "2022-02-03T01:24:48.988447Z",
     "iopub.status.idle": "2022-02-03T01:24:49.003488Z",
     "shell.execute_reply.started": "2022-02-03T01:24:48.988418Z",
     "shell.execute_reply": "2022-02-03T01:24:49.002499Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df['cleaned_tweets'] = df['tweets'].apply(cleaning)\n",
    "df['date'] = df_clean['date']\n",
    "df['date_clean'] = pd.to_datetime(df['date']).dt.strftime('%Y-%m-%d')\n",
    "df.drop(columns='date',inplace=True)\n",
    "df.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:25:40.313178Z",
     "iopub.execute_input": "2022-02-03T01:25:40.313472Z",
     "iopub.status.idle": "2022-02-03T01:25:47.780782Z",
     "shell.execute_reply.started": "2022-02-03T01:25:40.313444Z",
     "shell.execute_reply": "2022-02-03T01:25:47.779751Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def getSubjectivity(tweet):\n",
    "    return TextBlob(tweet).sentiment.subjectivity\n",
    "\n",
    "def getPolarity(tweet):\n",
    "    return TextBlob(tweet).sentiment.polarity"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:25:52.891424Z",
     "iopub.execute_input": "2022-02-03T01:25:52.891717Z",
     "iopub.status.idle": "2022-02-03T01:25:52.897299Z",
     "shell.execute_reply.started": "2022-02-03T01:25:52.891685Z",
     "shell.execute_reply": "2022-02-03T01:25:52.896Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def crypto_price_cate(score):\n",
    "    if score < 1:\n",
    "        return 'negative'\n",
    "    elif score == 1:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'positive'\n",
    "def observe_period(period):\n",
    "    res = crypto_usd_grouped.shift(period)/crypto_usd_grouped\n",
    "    res = res.apply(crypto_price_cate)\n",
    "    return res \n",
    "\n",
    "time_sentiment = observe_period(7) # compare price ratio in 7 days. price_7_days_later/ price_now \n",
    "df['crypto_sentiment'] = df.date_clean.apply(lambda x: time_sentiment[x] if x in time_sentiment else np.nan)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:33:02.684866Z",
     "iopub.execute_input": "2022-02-03T01:33:02.68565Z",
     "iopub.status.idle": "2022-02-03T01:33:07.627451Z",
     "shell.execute_reply.started": "2022-02-03T01:33:02.685613Z",
     "shell.execute_reply": "2022-02-03T01:33:07.626551Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# may takes time \n",
    "df['subjectivity'] = df['cleaned_tweets'].apply(getSubjectivity)\n",
    "df['polarity'] = df['cleaned_tweets'].apply(getPolarity)\n",
    "df.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:30:18.573839Z",
     "iopub.execute_input": "2022-02-03T01:30:18.574683Z",
     "iopub.status.idle": "2022-02-03T01:30:29.51939Z",
     "shell.execute_reply.started": "2022-02-03T01:30:18.574614Z",
     "shell.execute_reply": "2022-02-03T01:30:29.51819Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def getSentiment(score):\n",
    "    if score < 0:\n",
    "        return 'negative'\n",
    "    elif score == 0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'positive'\n",
    "df['sentiment'] = df['polarity'].apply(getSentiment)\n",
    "df['target'] = df['sentiment'] == df['crypto_sentiment']\n",
    "df.head()\n",
    "df.to_csv('./df_data.csv')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:31:56.684154Z",
     "iopub.execute_input": "2022-02-03T01:31:56.68444Z",
     "iopub.status.idle": "2022-02-03T01:31:57.13092Z",
     "shell.execute_reply.started": "2022-02-03T01:31:56.684412Z",
     "shell.execute_reply": "2022-02-03T01:31:57.130052Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model preparation "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow.keras.layers as Layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Conv1D, GlobalMaxPooling1D, Bidirectional, SpatialDropout1D\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:33:17.047467Z",
     "iopub.execute_input": "2022-02-03T01:33:17.048367Z",
     "iopub.status.idle": "2022-02-03T01:33:17.057856Z",
     "shell.execute_reply.started": "2022-02-03T01:33:17.048306Z",
     "shell.execute_reply": "2022-02-03T01:33:17.056417Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:33:18.487372Z",
     "iopub.execute_input": "2022-02-03T01:33:18.487697Z",
     "iopub.status.idle": "2022-02-03T01:33:18.503394Z",
     "shell.execute_reply.started": "2022-02-03T01:33:18.48766Z",
     "shell.execute_reply": "2022-02-03T01:33:18.502377Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X = df['cleaned_tweets']\n",
    "y = pd.get_dummies(df['sentiment']).values\n",
    "num_classes = df['sentiment'].nunique()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:33:31.743205Z",
     "iopub.execute_input": "2022-02-03T01:33:31.743473Z",
     "iopub.status.idle": "2022-02-03T01:33:31.755791Z",
     "shell.execute_reply.started": "2022-02-03T01:33:31.743447Z",
     "shell.execute_reply": "2022-02-03T01:33:31.755056Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "seed = 38 # fix random seed for reproducibility\n",
    "np.random.seed(seed)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=seed)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:33:34.526966Z",
     "iopub.execute_input": "2022-02-03T01:33:34.527987Z",
     "iopub.status.idle": "2022-02-03T01:33:34.734002Z",
     "shell.execute_reply.started": "2022-02-03T01:33:34.527911Z",
     "shell.execute_reply": "2022-02-03T01:33:34.732997Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "max_features = 20000\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(X_train))\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:33:37.265026Z",
     "iopub.execute_input": "2022-02-03T01:33:37.267286Z",
     "iopub.status.idle": "2022-02-03T01:33:38.206344Z",
     "shell.execute_reply.started": "2022-02-03T01:33:37.267213Z",
     "shell.execute_reply": "2022-02-03T01:33:38.205601Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "max_words = 30\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
    "print(X_train.shape,X_test.shape)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:33:38.20767Z",
     "iopub.execute_input": "2022-02-03T01:33:38.208357Z",
     "iopub.status.idle": "2022-02-03T01:33:38.367129Z",
     "shell.execute_reply.started": "2022-02-03T01:33:38.208314Z",
     "shell.execute_reply": "2022-02-03T01:33:38.366012Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Embedding,Conv1D,MaxPooling1D,LSTM\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "max_features = 20000\n",
    "embed_dim = 100\n",
    "\n",
    "np.random.seed(seed)\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embed_dim, input_length=X_train.shape[1]))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))    \n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:33:40.50759Z",
     "iopub.execute_input": "2022-02-03T01:33:40.507897Z",
     "iopub.status.idle": "2022-02-03T01:33:40.804896Z",
     "shell.execute_reply.started": "2022-02-03T01:33:40.507862Z",
     "shell.execute_reply": "2022-02-03T01:33:40.803693Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:33:42.532885Z",
     "iopub.execute_input": "2022-02-03T01:33:42.533165Z",
     "iopub.status.idle": "2022-02-03T01:33:42.776751Z",
     "shell.execute_reply.started": "2022-02-03T01:33:42.533137Z",
     "shell.execute_reply": "2022-02-03T01:33:42.776005Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "                          epochs=epochs, batch_size=batch_size, verbose=2)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:33:44.626147Z",
     "iopub.execute_input": "2022-02-03T01:33:44.626449Z",
     "iopub.status.idle": "2022-02-03T01:35:09.235118Z",
     "shell.execute_reply.started": "2022-02-03T01:33:44.626419Z",
     "shell.execute_reply": "2022-02-03T01:35:09.23423Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_training_hist(history):\n",
    "    '''Function to plot history for accuracy and loss'''\n",
    "    \n",
    "    fig, ax = plt.subplots(1,2, figsize=(10,4))\n",
    "    # first plot\n",
    "    ax[0].plot(history.history['accuracy'])\n",
    "    ax[0].plot(history.history['val_accuracy'])\n",
    "    ax[0].set_title('Model Accuracy')\n",
    "    ax[0].set_xlabel('epoch')\n",
    "    ax[0].set_ylabel('accuracy')\n",
    "    ax[0].legend(['train', 'validation'], loc='best')\n",
    "    \n",
    "    # second plot\n",
    "    ax[1].plot(history.history['loss'])\n",
    "    ax[1].plot(history.history['val_loss'])\n",
    "    ax[1].set_title('Model Loss')\n",
    "    ax[1].set_xlabel('epoch')\n",
    "    ax[1].set_ylabel('loss')\n",
    "    ax[1].legend(['train', 'validation'], loc='best')\n",
    "    \n",
    "plot_training_hist(history)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:19:30.09537Z",
     "iopub.execute_input": "2022-02-03T01:19:30.095624Z",
     "iopub.status.idle": "2022-02-03T01:19:30.479095Z",
     "shell.execute_reply.started": "2022-02-03T01:19:30.095594Z",
     "shell.execute_reply": "2022-02-03T01:19:30.478395Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# predict class with test set\n",
    "y_pred_test =  np.argmax(model.predict(X_test), axis=1)\n",
    "print('Accuracy:\\t{:0.1f}%'.format(accuracy_score(np.argmax(y_test,axis=1),y_pred_test)*100))\n",
    "print(classification_report(np.argmax(y_test,axis=1), y_pred_test))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:35:22.738854Z",
     "iopub.execute_input": "2022-02-03T01:35:22.739826Z",
     "iopub.status.idle": "2022-02-03T01:35:24.396029Z",
     "shell.execute_reply.started": "2022-02-03T01:35:22.739767Z",
     "shell.execute_reply": "2022-02-03T01:35:24.395341Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns \n",
    "def plot_confusion_matrix(model, X_test, y_test):\n",
    "    '''Function to plot confusion matrix for the passed model and the data'''\n",
    "    \n",
    "    sentiment_classes = ['Negative','Neutral', 'Positive']\n",
    "    # use model to do the prediction\n",
    "    y_pred = model.predict(X_test)\n",
    "    # compute confusion matrix\n",
    "    cm = confusion_matrix(np.argmax(y_pred, axis=1),np.argmax(np.array(y_test),axis=1))\n",
    "    \n",
    "    print(pd.Series(np.argmax(np.array(y_test),axis=1)).value_counts())\n",
    "    print(pd.Series(np.argmax(y_pred, axis=1)).value_counts())\n",
    "    \n",
    "    # plot confusion matrix\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm, cmap=plt.cm.Blues, annot=True, fmt='d', \n",
    "                xticklabels=sentiment_classes,\n",
    "                yticklabels=sentiment_classes)\n",
    "    plt.title('Confusion matrix', fontsize=16)\n",
    "    plt.xlabel('Actual label', fontsize=12)\n",
    "    plt.ylabel('Predicted label', fontsize=12)\n",
    "    \n",
    "plot_confusion_matrix(model, X_test, y_test)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:35:34.027643Z",
     "iopub.execute_input": "2022-02-03T01:35:34.028407Z",
     "iopub.status.idle": "2022-02-03T01:35:35.568164Z",
     "shell.execute_reply.started": "2022-02-03T01:35:34.028374Z",
     "shell.execute_reply": "2022-02-03T01:35:35.567299Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model2 "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_words = 5000\n",
    "max_len=50\n",
    "\n",
    "def tokenize_pad_sequences(text):\n",
    "    '''\n",
    "    This function tokenize the input text into sequnences of intergers and then\n",
    "    pad each sequence to the same length\n",
    "    '''\n",
    "    # Text tokenization\n",
    "    tokenizer = Tokenizer(num_words=max_words, lower=True, split=' ')\n",
    "    tokenizer.fit_on_texts(text)\n",
    "    # Transforms text to a sequence of integers\n",
    "    X = tokenizer.texts_to_sequences(text)\n",
    "    # Pad sequences to the same length\n",
    "    X = pad_sequences(X, padding='post', maxlen=max_len)\n",
    "    # return sequences\n",
    "    return X, tokenizer\n",
    "\n",
    "print('Before Tokenization & Padding \\n', df['cleaned_tweets'][0])\n",
    "X, tokenizer = tokenize_pad_sequences(df['cleaned_tweets'])\n",
    "print('After Tokenization & Padding \\n', X[0])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:35:49.239628Z",
     "iopub.execute_input": "2022-02-03T01:35:49.239992Z",
     "iopub.status.idle": "2022-02-03T01:35:50.440741Z",
     "shell.execute_reply.started": "2022-02-03T01:35:49.239956Z",
     "shell.execute_reply": "2022-02-03T01:35:50.439882Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "y = pd.get_dummies(df['sentiment'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "print('Train Set: ', X_train.shape, y_train.shape)\n",
    "print('Validation Set: ', X_val.shape, y_val.shape)\n",
    "print('Test Set: ', X_test.shape, y_test.shape)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:43:30.087663Z",
     "iopub.execute_input": "2022-02-03T01:43:30.08832Z",
     "iopub.status.idle": "2022-02-03T01:43:30.118826Z",
     "shell.execute_reply.started": "2022-02-03T01:43:30.088259Z",
     "shell.execute_reply": "2022-02-03T01:43:30.117882Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def f1_score(precision, recall):\n",
    "    ''' Function to calculate f1 score '''\n",
    "    \n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:43:54.297865Z",
     "iopub.execute_input": "2022-02-03T01:43:54.298166Z",
     "iopub.status.idle": "2022-02-03T01:43:54.303598Z",
     "shell.execute_reply.started": "2022-02-03T01:43:54.298137Z",
     "shell.execute_reply": "2022-02-03T01:43:54.302635Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Bidirectional, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import History\n",
    "from tensorflow.keras import losses"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:43:58.030324Z",
     "iopub.execute_input": "2022-02-03T01:43:58.030624Z",
     "iopub.status.idle": "2022-02-03T01:43:58.037199Z",
     "shell.execute_reply.started": "2022-02-03T01:43:58.030594Z",
     "shell.execute_reply": "2022-02-03T01:43:58.036405Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "vocab_size = 5000\n",
    "embedding_size = 32\n",
    "epochs = 50\n",
    "learning_rate = 0.01\n",
    "decay_rate = learning_rate / epochs\n",
    "momentum = 0.8"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:44:50.434678Z",
     "iopub.execute_input": "2022-02-03T01:44:50.435399Z",
     "iopub.status.idle": "2022-02-03T01:44:50.441408Z",
     "shell.execute_reply.started": "2022-02-03T01:44:50.435362Z",
     "shell.execute_reply": "2022-02-03T01:44:50.440141Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sgd = SGD(learning_rate=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "# Build model\n",
    "model= Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size, input_length=max_len))\n",
    "model.add(Conv1D(filters=32, kernel_size=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Bidirectional(LSTM(32)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(3, activation='softmax'))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:44:52.027807Z",
     "iopub.execute_input": "2022-02-03T01:44:52.028118Z",
     "iopub.status.idle": "2022-02-03T01:44:52.668989Z",
     "shell.execute_reply.started": "2022-02-03T01:44:52.028089Z",
     "shell.execute_reply": "2022-02-03T01:44:52.66788Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:44:52.671463Z",
     "iopub.execute_input": "2022-02-03T01:44:52.671776Z",
     "iopub.status.idle": "2022-02-03T01:44:52.927783Z",
     "shell.execute_reply.started": "2022-02-03T01:44:52.671746Z",
     "shell.execute_reply": "2022-02-03T01:44:52.9266Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy', Precision(), Recall()])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:44:54.051742Z",
     "iopub.execute_input": "2022-02-03T01:44:54.052045Z",
     "iopub.status.idle": "2022-02-03T01:44:54.07282Z",
     "shell.execute_reply.started": "2022-02-03T01:44:54.052017Z",
     "shell.execute_reply": "2022-02-03T01:44:54.071762Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "history = model.fit(X_train,y_train,validation_data=(X_val, y_val),batch_size=batch_size,epochs=epochs,verbose=1)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:44:56.750132Z",
     "iopub.execute_input": "2022-02-03T01:44:56.751154Z",
     "iopub.status.idle": "2022-02-03T01:49:39.688225Z",
     "shell.execute_reply.started": "2022-02-03T01:44:56.751101Z",
     "shell.execute_reply": "2022-02-03T01:49:39.687258Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Evaluate model on the test set\n",
    "loss, accuracy, precision, recall = model.evaluate(X_test, y_test, verbose=0)\n",
    "# Print metrics\n",
    "print('')\n",
    "print('Accuracy  : {:.4f}'.format(accuracy))\n",
    "print('Precision : {:.4f}'.format(precision))\n",
    "print('Recall    : {:.4f}'.format(recall))\n",
    "print('F1 Score  : {:.4f}'.format(f1_score(precision, recall)))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:51:31.378067Z",
     "iopub.execute_input": "2022-02-03T01:51:31.3785Z",
     "iopub.status.idle": "2022-02-03T01:51:32.958044Z",
     "shell.execute_reply.started": "2022-02-03T01:51:31.37846Z",
     "shell.execute_reply": "2022-02-03T01:51:32.95709Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plot_training_hist(history)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:51:32.960073Z",
     "iopub.execute_input": "2022-02-03T01:51:32.960574Z",
     "iopub.status.idle": "2022-02-03T01:51:33.341923Z",
     "shell.execute_reply.started": "2022-02-03T01:51:32.960529Z",
     "shell.execute_reply": "2022-02-03T01:51:33.341024Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plot_confusion_matrix(model, X_test, y_test)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T01:51:40.730242Z",
     "iopub.execute_input": "2022-02-03T01:51:40.730563Z",
     "iopub.status.idle": "2022-02-03T01:51:42.47863Z",
     "shell.execute_reply.started": "2022-02-03T01:51:40.730533Z",
     "shell.execute_reply": "2022-02-03T01:51:42.477902Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
